---
title: "Quantitative Thinking in Education: A Practical Guide to R-Based Research"
author: "Kuya Kevin"
format: html_book
site: bookdown::bookdown_site
output:
  bookdown::html_book:
    toc: true
    number_sections: true
    css: style.css
    split_by: chapter
---

# Introduction: Why R in Education?

Welcome to *Quantitative Thinking in Education: A Practical Guide to R-Based Computation*. This book is designed to support researchers, graduate students, and education professionals in learning to use R for insightful educational research; rigorous analytic computating that's associated in teaching; and in developing and validating assessment tools.

This book spans a wide range of topics — from evaluating interventions in the classroom, to modeling student success, to analyzing national assessments. Education, as a science and discipline, has evolved to evidence based findings following the "data driven" tradition. Data and computation have become central in this field.

## What is Educational Research?

Educational research is a multidisciplinary field that seeks to understand, improve, and evaluate educational processes and outcomes. It draws on theory and methods from psychology, sociology, economics, and policy studies. Whether you're measuring student motivation, assessing learning gains, or exploring systemic inequalities, data plays a critical role.

## Why Use R?

R is a powerful programming language and ecosystem for statistical computing and graphics. It’s particularly well-suited for education researchers because:

-   It supports open, reproducible workflows.
-   It has packages for psychometrics, multilevel modeling, survey analysis, and more.
-   It allows full transparency and customization, unlike point-and-click software.
-   It’s free, community-supported, and constantly evolving.

## Examples of R in Educational Research

R has been used across various studies and publications in education. Here are some examples:

1.  **Measuring School Effects on Student Achievement**\
    Goldstein, H., & Spiegelhalter, D. J. (1996). League tables and their limitations: Statistical issues in comparisons of institutional performance. *Journal of the Royal Statistical Society: Series A*, 159(3), 385–443.\
    ➤ Available via [JSTOR](https://www.jstor.org/stable/2983320)\
    ➤ Replication materials: Use multilevel modeling with `lme4`

2.  **Student Engagement and Predictors of Dropout**\
    Tinto, V. (1993). Leaving college: Rethinking the causes and cures of student attrition.\
    ➤ While the book itself doesn't use R, modern dropout prediction research often replicates Tinto’s framework using logistic regression or survival analysis in R.

3.  **Large-scale Assessment Analysis**\
    OECD PISA datasets (freely available):\
    ➤ Download from [PISA Data Portal](https://www.oecd.org/pisa/data/)\
    ➤ Many R packages (`intsvy`, `EdSurvey`) support analysis of these datasets. See tutorials like <https://www.r-bloggers.com/2021/02/analyzing-pisa-2018-data-in-r/>

4.  **Factor Analysis of Educational Surveys**\
    Pekrun, R. et al. (2011). Measuring emotions in students: The Achievement Emotions Questionnaire (AEQ). *Contemporary Educational Psychology*.\
    ➤ This paper’s scale can be replicated using `psych::fa()` with synthetic or provided AEQ data.

5.  **Educational Data Mining and Learning Analytics**\
    Ferguson, R. (2012). Learning analytics: Drivers, developments and challenges. *International Journal of Technology Enhanced Learning*.\
    ➤ Learning analytics with R includes tools like `tidylog`, `ggplot2`, `caret`, and `randomForest`.

## Try This: Replicating a Real Educational Study

We’ll revisit this in a later chapter, but here’s a teaser using OECD PISA data:

``` r
# install.packages("EdSurvey")
library(EdSurvey)

# Download PISA 2018 US student file (large dataset)
pisa <- readPISA(country = "USA", year = 2018)

# Examine gender gap in reading scores
gap <- gapTable(var = "PV1READ", by = "ST004D01T", data = pisa)
gap
```

This brief example shows how real-world, policy-relevant research can be done using R and publicly available education datasets.

## What This Book Covers

This book provides practical guidance through: - Hands-on code examples using real educational datasets - Theoretical grounding for each technique - Reproducible R Notebooks

Each chapter will be paired with an `.Rmd` or `.qmd` notebook for readers to explore and adapt to their own research.

# Chapter 1: Getting Started with R and RStudio

## Installing R, RStudio, and Quarto

To follow along with this book, you'll need:

-   [R](https://cran.r-project.org/) (the core language)
-   [RStudio](https://posit.co/download/rstudio-desktop/) (the integrated development environment)
-   [Quarto](https://quarto.org/) (for publishing notebooks and books)

After installation, open RStudio and install the core packages:

``` r
install.packages(c("tidyverse", "psych", "lme4", "bookdown", "quarto"))
```

## Setting Up Your First Project

Use RStudio Projects to keep your work organized and reproducible:

-   File \> New Project \> New Directory \> Book Project using bookdown

Use the `here` package to avoid hardcoding file paths:

``` r
install.packages("here")
library(here)
here("data", "scores.csv")
```

## Installing and Loading Packages

Use `install.packages()` once, and `library()` every time you use R:

``` r
install.packages("psych")
library(psych)
```

Use `renv::init()` to lock package versions in collaborative or long-term projects.

## Writing Notebooks with Quarto

Use `.qmd` files for combining code and text. For example:

```{{r}}
summary(mtcars)
```

You can knit to HTML, PDF, or Word using the Render button.

## Running Your First Analysis

Let’s try a simple task:

``` r
data(mtcars)
summary(mtcars$mpg)
hist(mtcars$mpg)
```

Now you’ve installed R, loaded a dataset, explored it, and visualized it — all within a reproducible notebook.

# Chapter 2: Data Wrangling for Educational Research

Data wrangling is the essential process of cleaning, transforming, and structuring raw data into a usable format for analysis. In educational research, datasets often originate from diverse sources like student information systems, national surveys, classroom assessments, or administrative records. These raw datasets are rarely ready for immediate analysis and require extensive preparation to handle inconsistencies, missing information, and structural issues before they can be used for statistical modeling or visualization.

According to Grolemund and Wickham (2019), data wrangling is the single most time-consuming task in data science, often occupying up to 80% of a researcher’s time. For educational studies, tasks such as handling missing values from student surveys, recoding demographic variables (e.g., socioeconomic status), merging student assessment data with school-level data, and creating composite scores are fundamental for ensuring the validity and reliability of research findings (Schneider et al., 2018).

## 2.1 Principles of Tidy Data

Hadley Wickham (2014) introduced the powerful concept of **tidy data**, which provides a standard way to organize data values within a data frame.

::: callout-note
## Tidy Data Principles

A dataset is considered tidy if it adheres to these three principles: 1. Each **variable** forms a **column**. 2. Each **observation** forms a **row**. 3. Each type of observational unit forms a **separate table**.
:::

In education, this means that a single row should represent a single observational unit—like one student's response to one survey item or one student's score on one test. This structure simplifies analysis and is the default format expected by most analytical and visualization tools in R.

### Example: From Wide to Tidy Data

Educational data is often recorded in a "wide" format, where columns represent values instead of variables.

A **messy (wide) dataset** might look like this:

| student_id | math_score | reading_score | science_score |
|:-----------|:-----------|:--------------|:--------------|
| 101        | 88         | 92            | 85            |
| 102        | 76         | 81            | 79            |
| 103        | 95         | 90            | 93            |

The tidy format restructures this data so that `math`, `reading`, and `science` are values of a `subject` variable.

A **tidy (long) dataset** looks like this:

| student_id | subject | score |
|:-----------|:--------|:------|
| 101        | math    | 88    |
| 101        | reading | 92    |
| 101        | science | 85    |
| 102        | math    | 76    |
| ...        | ...     | ...   |

This tidy structure is more flexible for analysis, such as calculating the average score per student or comparing scores across subjects.

## 2.2 Core Packages for Wrangling

The `tidyverse` suite (Wickham et al., 2019) is the cornerstone of modern data wrangling in R.

```{r}
#| label: load-packages
#| message: false
#| warning: false

# The first time, you may need to run: install.packages("tidyverse")
library(tidyverse)
```

Key packages within the `tidyverse` include: \* **`dplyr`**: For data manipulation (`filter()`, `select()`, `mutate()`, etc.). \* **`tidyr`**: For tidying data (`pivot_longer()`, `pivot_wider()`). \* **`readr`**: For importing rectangular data (e.g., `.csv`). \* **`stringr`**: For working with text data. \* **`forcats`**: For handling categorical variables (factors).

## 2.3 Importing Educational Datasets

Your first step is always to get the data into R.

```{r}
#| label: import-examples
#| eval: false
#| echo: true

# This code is for demonstration and will not run without the files.

# Import assessment data from a CSV file
student_scores <- read_csv("data/fall_2024_assessments.csv")

# Import demographic data from an Excel file
library(readxl)
student_demographics <- read_excel("data/student_records.xlsx", sheet = "Student Demographics")

# Import PISA data from an SPSS (.sav) file
library(haven)
pisa_student_questionnaire <- read_sav("data/pisa2018_student.sav")
```

## 2.4 Cleaning and Transforming Data 📊

This section demonstrates common wrangling tasks on sample data.

### Handling Missing Values

First, let's create a sample dataset with missing values (`NA`).

```{r}
#| label: create-missing-data

scores_data <- tibble(
  student_id = c(101, 102, 103, 104, 105),
  math_score = c(88, 76, NA, 92, 85),
  reading_score = c(90, NA, 85, 88, 91)
)
```

**Identify Missing Data**

```{r}
#| label: identify-missing

# Count missing values in each column
colSums(is.na(scores_data))
```

**Remove Missing Data**

```{r}
#| label: remove-missing

# Remove any row that contains at least one NA
scores_complete <- scores_data %>% drop_na()
print(scores_complete)
```

**Impute Missing Data**

```{r}
#| label: impute-missing

# Impute missing 'math_score' with the mean
scores_imputed <- scores_data %>%
  mutate(math_score = ifelse(is.na(math_score),
                             mean(math_score, na.rm = TRUE),
                             math_score))
print(scores_imputed)
```

### Recoding Variables

Let's create sample data with numeric codes.

```{r}
#| label: create-recode-data
student_data_demo <- tibble(
  student_id = 1:4,
  parental_income = c(25000, 55000, 120000, 74000)
)
```

We can use `case_when()` to create SES brackets.

```{r}
#| label: recode-ses

student_data_demo <- student_data_demo %>%
  mutate(
    ses_group = case_when(
      parental_income < 30000 ~ "Low",
      parental_income >= 30000 & parental_income < 75000 ~ "Medium",
      parental_income >= 75000 ~ "High",
      TRUE ~ NA_character_
    )
  )
print(student_data_demo)
```

### Joining Datasets

Let's create two sample tables to join.

```{r}
#| label: create-join-data
demographics_table <- tibble(
  student_id = c("S01", "S02", "S03"),
  gender = c("Male", "Female", "Female")
)
scores_table <- tibble(
  student_id = c("S01", "S02", "S04"),
  test_score = c(88, 95, 76)
)
```

A `left_join()` keeps all rows from the left table (`demographics_table`).

```{r}
#| label: perform-join
full_data <- left_join(demographics_table, scores_table, by = "student_id")
print(full_data)
```

Notice that student S03 has an `NA` for `test_score` (no match in `scores_table`), and student S04 from `scores_table` was dropped.

## 2.5 Case Study: Preprocessing a School District Dataset

This case study demonstrates a full, reproducible workflow.

**1. Create Sample Raw Data** In a real project, this step would be `read_csv()`. Here, we create the data frames directly so the notebook can run independently.

```{r}
#| label: case-study-create-data

demographics <- tribble(
  ~student_id, ~gender, ~ses_category,
  "A101", 1, 3,
  "A102", 2, 1,
  "A103", 2, 2,
  "A104", 1, 3
)

assessments <- tribble(
  ~student_id, ~subject, ~score,
  "A101", "Math", 85,
  "A101", "Reading", 88,
  "A102", "Math", 72,
  "A102", "Reading", 78,
  "A103", "Math", 91,
  "A103", "Reading", 94,
  "A104", "Math", 79,
  "A104", "Reading", NA
)
```

**2. Inspect and Reshape Assessment Data** We use `pivot_wider()` to create separate columns for Math and Reading scores.

```{r}
#| label: case-study-pivot

assessments_wide <- assessments %>%
  pivot_wider(
    names_from = subject,
    values_from = score
  ) %>%
  rename(math_score = Math, reading_score = Reading)

print(assessments_wide)
```

**3. Join Datasets**

```{r}
#| label: case-study-join
student_dataset <- left_join(demographics, assessments_wide, by = "student_id")
print(student_dataset)
```

**4. Clean and Recode Variables** Let's convert the numeric codes for `gender` and `ses_category` into descriptive factors.

```{r}
#| label: case-study-recode

student_dataset_clean <- student_dataset %>%
  mutate(
    gender = recode(gender, `1` = "Female", `2` = "Male"),
    ses = factor(ses_category, levels = c(1, 2, 3), labels = c("Low", "Medium", "High"))
  ) %>%
  select(-ses_category) # Drop the old numeric column

print(student_dataset_clean)
```

**5. Create a Derived Variable**

```{r}
#| label: case-study-mutate
student_dataset_final <- student_dataset_clean %>%
  mutate(
    average_score = (math_score + reading_score) / 2
  )

print(student_dataset_final)
```

**6. Final Analysis** The data is now wrangled. We can easily compute summary statistics.

```{r}
#| label: case-study-summarize
final_summary <- student_dataset_final %>%
  group_by(ses, gender) %>%
  summarize(
    count = n(),
    avg_math = mean(math_score, na.rm = TRUE),
    avg_reading = mean(reading_score, na.rm = TRUE),
    avg_total = mean(average_score, na.rm = TRUE),
    .groups = "drop" # Drop grouping for the final tibble
  )

print(final_summary)
```

This summary table is ready for reporting or visualization.

## 2.6 Best Practices for Data Management

::: {.callout-tip title="Best Practices for Data Management ✨"}
To ensure your research is transparent, reproducible, and credible, follow these best practices:

-   **Always keep a raw copy of the original dataset.** Never overwrite your raw data file. Treat it as read-only.
-   **Use scripts for all cleaning steps.** Avoid manual editing in spreadsheet software like Excel ("point-and-click"). Scripts provide a record of every transformation you made.
-   **Document your code with comments.** Explain *why* you are making a change, not just *what* the code does. This helps you and others understand your logic later.
-   **Organize your project in folders.** A typical structure includes folders for `data/raw`, `data/processed`, `scripts`, and `output/figures`.
-   **Use version control.** Tools like Git help you track changes to your scripts over time, preventing catastrophic mistakes and making collaboration easier.
:::

## References

-   Grolemund, G., & Wickham, H. (2019). *R for Data Science: Import, Tidy, Transform, Visualize, and Model Data*. O’Reilly Media.
-   Schneider, B., Carnoy, M., Kilpatrick, J., Schmidt, W. H., & Shavelson, R. J. (2018). *Estimating Causal Effects Using Experimental and Observational Designs: A Think Tank White Paper*. American Educational Research Association.
-   Wickham, H. (2014). Tidy Data. *Journal of Statistical Software*, 59(10), 1–23.
-   Wickham, H., et al. (2019). Welcome to the tidyverse. *Journal of Open Source Software*, 4(43), 1686.

# **Chapter 3: Descriptive and Inferential Statistics in Education**

## **3.1 Descriptive Statistics: Understanding Educational Data**

Descriptive statistics transform raw educational data into meaningful summaries, enabling educators to identify patterns, spot outliers, and understand distributions.

### **Central Tendency Measures:**

-   **Mean**: Arithmetic average (sensitive to outliers)\
    *Educational Use*: Calculating average test scores for grade-level comparisons

    r

    ```         
    mean(student_scores)
    ```

-   **Median**: Middle value in ordered data (robust to outliers)\
    *Educational Use*: Reporting typical family income in school demographic reports

    r

    ```         
    median(student_scores)
    ```

-   **Mode**: Most frequent value\
    *Educational Use*: Identifying most common misconception in assessment responses

### **Variability Measures:**

-   **Range**: Difference between maximum and minimum\
    *Educational Use*: Highlighting achievement gaps within classrooms

    r

    ```         
    range(student_scores)
    ```

-   **Variance**: Average squared deviation from mean

    r

    ```         
    var(student_scores)
    ```

-   **Standard Deviation**: Average deviation from mean (same units as data)\
    *Educational Use*: Measuring consistency in rubric-based scoring

    r

    ```         
    sd(student_scores)
    ```

-   **IQR**: Middle 50% of data (Q3-Q1)\
    *Educational Use*: Identifying typical growth percentiles

    r

    ```         
    IQR(student_scores)
    ```

### **Distribution Characteristics:**

-   **Skewness**: Asymmetry measure (positive = right-skewed)\
    *Educational Use*: Detecting ceiling effects in mastery assessments

    r

    ```         
    library(moments) skewness(student_scores)
    ```

-   **Kurtosis**: Tail heaviness (positive = heavy tails)\
    *Educational Use*: Checking normality for standardized tests

    r

    ```         
    kurtosis(student_scores)
    ```

## **3.2 Statistical Tests: Assumptions and Diagnostics**

All inferential tests require specific assumptions. Violations necessitate non-parametric alternatives.

### **Parametric Test Assumption Framework:**

1.  **Normality**: Residuals normally distributed

2.  **Homoscedasticity**: Equal variances across groups

3.  **Independence**: Observations not correlated

4.  **Interval/Ratio Data**: Continuous measurement scale

## **3.3 Common Inferential Tests with Diagnostics and Alternatives**

### **1. Independent t-test**

**Purpose**: Compare means between two independent groups (e.g., control vs. treatment)\
**Assumptions**:

-   Normality within groups

-   Homogeneity of variances

-   Interval/ratio data

**Diagnostics**:

r

```         
# Shapiro-Wilk normality test tapply(math_scores$score, math_scores$gender, shapiro.test)  # Levene's test for equal variances library(car) leveneTest(score ~ gender, data = math_scores)
```

**Implementation**:

r

```         
t.test(score ~ gender, data = math_scores, var.equal = TRUE)
```

**Non-parametric Alternative**: Mann-Whitney U Test

r

```         
wilcox.test(score ~ gender, data = math_scores)
```

### **2. Paired t-test**

**Purpose**: Compare pre-post measurements (e.g., before/after intervention)\
**Assumptions**:

-   Normality of difference scores

-   Interval/ratio data

**Diagnostics**:

r

```         
# Check difference score distribution diff_scores <- pre_test - post_test shapiro.test(diff_scores)
```

**Implementation**:

r

```         
t.test(pre_test, post_test, paired = TRUE)
```

**Non-parametric Alternative**: Wilcoxon Signed-Rank Test

r

```         
wilcox.test(pre_test, post_test, paired = TRUE)
```

### **3. One-Way ANOVA**

**Purpose**: Compare ≥3 group means (e.g., teaching methods)\
**Assumptions**:

-   Normality within groups

-   Homogeneity of variances

-   Independence

**Diagnostics**:

r

```         
# Normality by group tapply(method_data$scores, method_data$method, shapiro.test)  # Homogeneity of variances bartlett.test(scores ~ method, data = method_data)
```

**Implementation**:

r

```         
anova_model <- aov(scores ~ method, data = method_data) summary(anova_model)
```

**Non-parametric Alternative**: Kruskal-Wallis Test

r

```         
kruskal.test(scores ~ method, data = method_data)
```

### **4. Pearson Correlation**

**Purpose**: Measure linear relationship between continuous variables\
**Assumptions**:

-   Linear relationship

-   Bivariate normality

-   Homoscedasticity

**Diagnostics**:

r

```         
# Visual checks library(ggpubr) ggscatter(data.frame(reading, math), x="reading", y="math",            add = "reg.line") +   stat_cor(method = "pearson")  # Normality tests shapiro.test(reading) shapiro.test(math)
```

**Implementation**:

r

```         
cor.test(reading, math, method = "pearson")
```

**Non-parametric Alternative**: Spearman's Rank Correlation

r

```         
cor.test(reading, math, method = "spearman")
```

### **5. Chi-Square Test**

**Purpose**: Test association between categorical variables\
**Assumptions**:

-   Independence of observations

-   Expected frequencies ≥5

**Diagnostics**:

r

```         
# Check expected frequencies chisq.test(participation_table)$expected
```

**Implementation**:

r

```         
chisq.test(participation_table)
```

**Non-parametric Alternative**: Fisher's Exact Test

r

```         
fisher.test(participation_table)
```

## **3.4 Effect Size Reporting Standards**

Statistical significance ≠ practical importance. Effect sizes quantify magnitude:

| **Test**    | **Effect Size**  | **Interpretation**                  |
|:------------|:-----------------|:------------------------------------|
| t-test      | Cohen's d        | 0.2=small, 0.5=medium, 0.8=large    |
| ANOVA       | η² (eta-squared) | 0.01=small, 0.06=medium, 0.14=large |
| Correlation | r                | 0.1=small, 0.3=medium, 0.5=large    |
| Chi-square  | Cramer's V       | 0.1=small, 0.3=medium, 0.5=large    |

**R Implementation**:

r

```         
# Cohen's d for t-test library(effsize) cohen.d(score ~ gender, data = math_scores)  # Eta-squared for ANOVA library(effectsize) eta_squared(anova_model)
```

## **3.5 Handling Assumption Violations**

When assumptions aren't met:

1.  **Transformations**: Apply log/square root to skewed data

    r

    ```         
    log_scores <- log(student_scores)
    ```

2.  **Robust Methods**: Use trimmed means or bootstrap

    r

    ```         
    # 20% trimmed mean mean(student_scores, trim = 0.2)
    ```

3.  **Non-parametric Tests**: As shown above

4.  **Mixed Models**: For dependent observations

    r

    ```         
    library(lme4) lmer(score ~ method + (1|classroom), data = class_data)
    ```

## **3.6 Educational Data Considerations**

1.  **Nested Data**: Students within classrooms require multilevel modeling

2.  **Repeated Measures**: Longitudinal data need specialized approaches (e.g., growth modeling)

3.  **Missing Data**: Use multiple imputation instead of deletion

    r

    ```         
    library(mice) imputed_data <- mice(education_data, m=5)
    ```

4.  **Multiple Testing**: Adjust α using Bonferroni or FDR methods

    r

    ```         
    p.adjust(p_values, method = "fdr")
    ```

## **3.7 Reporting Best Practices**

1.  **APA Standards**:\
    "Reading scores significantly increased after intervention (M=85.2, SD=4.1 vs. M=78.6, SD=5.3), t(24)=4.32, p\<.001, d=0.92, 95% CI \[3.2, 9.9\]."

2.  **Transparency**:

    -   Report assumption checks

    -   Include effect sizes and confidence intervals

    -   Provide data and analysis scripts

3.  **Visualization**: Always complement statistics with graphs

r

```         
ggplot(math_scores, aes(x=gender, y=score)) +    geom_violin(trim=FALSE, fill="skyblue") +   geom_boxplot(width=0.1) +   stat_summary(fun=mean, geom="point", size=3, color="red") +   labs(title="Math Achievement by Gender",         subtitle="Violin plot with mean (red dot) and boxplot",        caption=paste0("t(", t_result$parameter,")=",                       round(t_result$statistic,2),                       ", p=", format.pval(t_result$p.value, eps=0.001)))
```

## **3.8 Suggested Resources**

-   **Assumption Diagnostics**:\
    Fox, J. & Weisberg, S. (2019). *An R Companion to Applied Regression*

-   **Non-parametric Methods**:\
    Hollander, M., Wolfe, D.A., & Chicken, E. (2014). *Nonparametric Statistical Methods*

-   **Educational Applications**:\
    Keith, T.Z. (2019). *Multiple Regression and Beyond*

*Statistical analysis in education requires both technical competence and contextual understanding. As noted by Berliner (2002), "The most significant educational decisions should be informed by data, but never determined solely by them."*

# Chapter 4: Psychometrics and Measurement *(Coming Soon)*

# Chapter 5: Multilevel Modeling *(Coming Soon)*

# Chapter 6: Program and Policy Evaluation *(Coming Soon)*

# Chapter 7: Visualizing Educational Data *(Coming Soon)*

# Chapter 8: Survey and Large-scale Assessment Analysis *(Coming Soon)*

# Chapter 9: Reproducible Research and Project Management *(Coming Soon)*

# Chapter 10: Publishing and Sharing Your Work *(Coming Soon)*
